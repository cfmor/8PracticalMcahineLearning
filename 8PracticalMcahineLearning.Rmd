---
title: "8 Practical Machine Learning Project"
author: "cfmor"
date: "29/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Course Project

This document includes all the steps done in the 8th course project for the 
coursera's Data Science Specialization. Therefore, a brief description of the 
task, the used data, the procedure, and the obtained results are shown.

### Goal

The goal of this project is to predict the manner in which the subjects did the 
exercise. This is the "classe" variable in the training set. It may be used any 
of the other variables to predict with. It should be created a report describing 
how the model was built, how cross validation was used, what is thought to be the 
expected out of sample error, and why the choices were made. The prediction model 
will be used to predict 20 different test cases. 

### Background

Using devices such as _Jawbone Up_, _Nike FuelBand_, and _Fitbit_ it is now 
possible to collect a large amount of data about personal activity relatively 
inexpensively. These type of devices are part of the quantified self movement â€“ 
a group of enthusiasts who take measurements about themselves regularly to improve 
their health, to find patterns in their behavior, or because they are tech geeks. 
One thing that people regularly do is quantify how _much_ of a particular activity 
they do, but they rarely quantify _how well they do it_. In this project, your 
goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell 
of 6 participants. They were asked to perform barbell lifts correctly and 
incorrectly in 5 different ways. More information is available from the website here:<http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har> 
(see the section on the Weight Lifting Exercise Dataset).

### Data

The data used in this project is sourced from the following sites.

The training data for this project are available here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

The test data are available here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

The data for this project come from this source: <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>. 
If you use the document you create for this class for any purpose please cite 
them as they have been very generous in allowing their data to be used for this 
kind of assignment.

## Retrieving and cleaning the data.

This section contains the procedure applied to the raw data in order to get the 
dataset to be used in the machine learning model.
```{r retrieve_and_clean_data, echo=TRUE}
# Load packages.
library(data.table)
library(naniar)
library(tidyr)
library(dplyr)

# Retrieve train and test sets.
trainset <- data.table::fread("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testset <- data.table::fread("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

# Visualize data (train).
summary(trainset)
# Checking missing data estimate.
vis_miss(trainset, warn_large_data=FALSE)
# It is seen that there are many columns with almost only NA values, these are dropped.
trainset <- trainset %>%
                select_if(~ !any(is.na(.)))
vis_miss(trainset, warn_large_data=FALSE)
# Variables like timestamp, subject and id are not require, since they don't give valuable information or they will cause overfitting.
trainset <- select(trainset, -c(names(trainset)[1:7]))
# Turn the classe into numerical value.
# trainset$classe <- match(trainset$classe, c(unique(trainset$classe)))
```

## Machine learning model.
``` {r train_split}
library(caret)
set.seed(33)
# Split the data into train and test sets.
inTrain = createDataPartition(trainset$classe, p=0.75, list=FALSE)
traintrain = trainset[ inTrain,]
traintest = trainset[-inTrain,]
```

### Training phase.
```{r train_models}
# Training different models: random forest classifier, classification tree, linear discriminant analysis classifier.
modRF <- train(classe ~.,
               data=traintrain,
               method="rf",
               preProcess=c("pca"),
               trControl=trainControl(method="cv", number=5))

modCT <- train(classe ~., 
               data=traintrain, 
               method="rpart",
               preProcess=c("pca"),
               trControl=trainControl(method="cv", number=5))

modLDA <- train(classe ~., 
                data=traintrain, 
                method="lda",
                preProcess=c("pca"),
                trControl=trainControl(method="cv", number=5))
```

### Testing phase.
``` {r test_models}
## Random forest classifier.
# Get predictions.
testRF <- predict(modRF, traintest)
# Evaluate the results.
print(cmRF <- confusionMatrix(table(traintest$classe, testRF)))
print(accuracyRF <- cmRF$overall[1])
```

``` {r test_models2}
## Classification tree.
# Get predictions.
testCT <- predict(modCT, traintest)
# Evaluate the results.
print(cmCT <- confusionMatrix(table(traintest$classe, testCT)))
print(accuracyCT <- cmCT$overall[1])
```

``` {r test_models3}
## Linear discriminant analysis classifier.
# Get predictions.
testLDA <- predict(modLDA, traintest)
# Evaluate the results.
print(cmLDA <- confusionMatrix(table(traintest$classe, testLDA)))
print(accuracyLDA <- cmLDA$overall[1])

```
### Predicting phase.
``` {r predictions}
# Subset same columns as in training.
testset <- testset %>%
                select_if(~ !any(is.na(.))) %>%
                select(-c(names(testset)[1:7]))

# Get predictions with best model (random forest classifier).
print(predictions <- predict(modRF, testset))
                
```

## Results.

After testing the following models:random forest classifier, classification tree, linear discriminant analysis classifier; as the random forest classifier had the best overall accuracy (0.98) it was chosen to make the predictions of the new (unknown) _classes_.
The following predictions were obtained:

B A A A A E D B A A B C B A E E A B B B.

It must be noted however, that the used classifier used considerably more time to be trained than the other two verified models.